%\usepackage[a4paper, margin=1in]{geometry}
\documentclass[11pt]{article}
% use UTF8 encoding
\usepackage[utf8]{inputenc}
% use KoTeX package for Korean
\usepackage[hangulfontspec, nohangul]{kotex}

\usepackage{glossaries}
\usepackage{graphicx}
\usepackage{titling}

\usepackage{amsmath}
\setlength{\parindent}{15pt}  % 들여쓰기 크기 설정 (기본: 15pt)


\makeglossaries
\newacronym{cstr}{CSTR}{Continuous Stirred Tank Reactor}
\newacronym{rl}{RL}{Reinforcement Learning}
\newacronym{dqn}{DQN}{Deep Q-Network}
\newacronym{ppo}{PPO}{Proximal Policy Optimization}
\newacronym{ddpg}{DDPG}{Deep Deterministic Policy Gradient}
\newacronym{pid}{PID}{Proportional-Integral-Derivative}
\newacronym{mpc}{MPC}{Model Predictive Control}

\begin{document}

\title{RL-Based Control of Benchmark CSTR Processes with Safety Considerations}
\author{Seunghyun Cho, Hain Lee, Jaehyun Oh}
\date{\today}


\setlength{\droptitle}{-4cm}  % 제목과 페이지 상단 간격 조정
\maketitle

 
\section{Backgrounds}
\subsection{CSTR}
\gls{cstr} is a representative chemical reactor in which fluid is continuously fed, and reaction and mixing occur simultaneously. 
It is assumed that the reactants are perfectly mixed within the reactor, and the system is characterized by dynamic features such as reaction rate, concentration, and temperature. 
In particular, due to nonlinearity, even small input variations or noises can significantly affect the system behavior. Thus, this system requires precise control strategies.


\subsection{Process Control}
Process Control is a field of engineering that aims to ensure stable operation and optimal performance of industrial processes.
It is utilized in various industries such as chemical, petrochemical, and pharmaceutical to control variables (e.g., temperature, pressure, flow rate) of various equipment including reactors, distillation columns, and heat exchangers. 
Due to complex process characteristics such as nonlinearity and time delay, control methods beyond traditional \gls{pid} control—such as \gls{mpc} and reinforcement learning-based approaches—are being actively studied.


\section{Project Summary}
The failure of Process Control can directly lead to safety issues. 
Due to the nonlinear characteristics of the CSTR process, it poses challenges in control, requiring more flexible and adaptive control strategies. 
Despite the importance of safety, only a few studies have focused on utilizing reinforcement learning methods to \gls{cstr} processes in the context of safety.
This project aims to address this gap by proposing an RL-based control framework that explicitly considers safety constraints in the operation of \gls{cstr} processes. \\ 
Accordingly, this study applies deep reinforcement learning algorithms such as \gls{dqn}, \gls{ppo}, and \gls{ddpg} to perform dynamic control of the process, 
and seeks to validate the variation in control performance and potential for ensuring process stability depending on reward function design through the Van de Vusse reaction, a benchmark for \gls{cstr} processes.


\section{Related Works}


\subsection{Library}
Bloor et al. increased the accessibility of RL research in Process Control by proposing a standardized environment for the field.\cite{MaximilianB2pcgym}


\subsection{Previous Researchs}
Park et al. improved control performance by 12\% compared to MPC by optimizing the reward function considering the nonlinearity of the CSTR.\cite{Park2024rl} 
Yu et al. successfully achieved stable control of the CSTR using a PPO-based control framework, even under disturbances.\cite{Yu2025ppo}
Bloor et al. proposed a standardized environment for comparing the performance of reinforcement learning and nonlinear MPC.\cite{bloor2024pcgym} 
Chen et al. (1995) provided an initial benchmark for the nonlinear control problem of CSTR, laying the foundation for subsequent studies.\cite{chen1995benchmark}
Additionally, Park et al. provided a comprehensive review of RL applications in Process Control, confirming its effectiveness in controlling the complex dynamics of the CSTR.\cite{Park2025pc}


\section{Project Milestones}
1. Modify the reaction equation in the PC-Gym library to describe the Van de Vusse reaction, and add the Tank Level used in \cite{Yu2025ppo} as an additional consideration. 
Redefine the corresponding States and Actions to suit this new configuration.\\
2. Implement baseline models for each algorithm using \gls{dqn}, \gls{ppo}, and \gls{ddpg}.\\
3. Adjust the reward function and explore methods to enhance the benchmark performance of each baseline model.

\bibliographystyle{IEEEtran}
\bibliography{references}


\end{document}
